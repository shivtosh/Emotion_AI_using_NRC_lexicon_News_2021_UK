{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af565ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "#from nrclex import NRCLex\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import string\n",
    "import os, re, csv, json, sys, string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import gzip\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle as pkl\n",
    "from argparse import ArgumentParser\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20afb627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_lexicon(path, LEXNAMES):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df[~df['word'].isna()]\n",
    "    df = df[['word']+LEXNAMES]\n",
    "    df['word'] = [x.lower() for x in df['word']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de2a1017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dim_lexicon(df, dim):\n",
    "    ldf = df[['word']+[dim]]\n",
    "    ldf = ldf[~ldf[dim].isna()]\n",
    "    ldf.drop_duplicates(subset=['word'], keep='first', inplace=True)\n",
    "    ldf[dim] = [float(x) for x in ldf[dim]]\n",
    "    ldf.rename({dim: 'val'}, axis='columns', inplace=True)\n",
    "    ldf.set_index('word', inplace=True)\n",
    "    return ldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af202264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alpha(token):\n",
    "    return token.isalpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f005ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vals(twt, lexdf):\n",
    "    tt = twt.lower().split(\" \")\n",
    "    at = [w for w in tt if w.isalpha()]\n",
    "\n",
    "    pw = [x for x in tt if x in lexdf.index]\n",
    "    pv = [lexdf.loc[w]['val'] for w in pw]\n",
    "\n",
    "    numTokens = len(at)\n",
    "    numLexTokens = len(pw)\n",
    "    \n",
    "    avgLexVal = np.mean(pv)  #nan for 0 tokens\n",
    "\n",
    "    return [numTokens, numLexTokens, avgLexVal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b878fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_df(df, lexdf):\n",
    "    logging.info(\"Number of rows: \" + str(len(df)))\n",
    "\n",
    "    resrows = [get_vals(x, lexdf) for x in df['text']]\n",
    "    resrows = [x + y for x,y in zip(df.values.tolist(), resrows)]\n",
    "\n",
    "    resdf = pd.DataFrame(resrows, columns=df.columns.tolist() + ['numTokens', 'numLexTokens', 'avgLexVal'])\n",
    "    resdf = resdf[resdf['numLexTokens']>=1]\n",
    "    \n",
    "    resdf['lexRatio'] = resdf['numLexTokens']/resdf['numTokens']\n",
    "    return resdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be1bac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dataPath, LEXICON, LEXNAMES, savePath):\n",
    "\n",
    "    os.makedirs(savePath, exist_ok=True)\n",
    "\n",
    "    logfile = os.path.join(savePath, 'log.txt')\n",
    "\n",
    "    logging.basicConfig(filename=logfile, format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "    \n",
    "    df = pd.read_csv(dataPath,index_col=False)\n",
    "    df.text=df.text.astype(str)\n",
    "    \n",
    "\n",
    "    for LEXNAME in LEXNAMES:\n",
    "\n",
    "        lexdf = prep_dim_lexicon(LEXICON, LEXNAME)\n",
    "        logging.info(LEXNAME + \" lexicon length: \" + str(len(lexdf)))\n",
    "        resdf = process_df(df, lexdf)\n",
    "    \n",
    "        resdf.to_csv(os.path.join(savePath, LEXNAME+'.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1b81a29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    \n",
    "\n",
    "    dataPath = \"C:/Users/WELCOME/Downloads/data/preprocessed_data_final.csv\"\n",
    "    lexPath = \"C:/Users/WELCOME/Downloads/data/lexicon.csv\"\n",
    "\n",
    "    LEXNAMES = [\"Positive\",\"Negative\",\"Anger\",\"Anticipation\",\"Disgust\",\"Fear\",\"Joy\",\"Sadness\",\"Surprise\",\"Trust\"]\n",
    "    LEXICON = read_lexicon(lexPath, LEXNAMES)\n",
    "\n",
    "    savePath = \"C:/Users/WELCOME/Downloads/data/emo_dyn\"\n",
    "\n",
    "    main(dataPath, LEXICON, LEXNAMES, savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3cff3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da34aea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c57e2b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
